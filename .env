# --- Telegram / Infra ---
TG_TOKEN=8072401817:AAGMlcJNjZre08-DYLMRJ_kTwmHDOgoW4R4
REDIS_URL=redis://localhost:6379/0

# --- LLM endpoint / model ---
LLM_URL=http://127.0.0.1:8080/v1/chat/completions
# Выставь под фактический файл, с которым запускаешь llama-server:
LLM_MODEL=/home/len/rpgbot/core/weights/Qwen3-14B-Q5_K_M.gguf

# --- Sampling (top_p) ---
STRUCT_TOP_P=0.0
PRIVATE_TOP_P=0.90
GENERAL_TOP_P=0.92
SESSION_INIT_TOP_P=0.92

# Только для строгих структур (Effects) фиксируем сид.
# Для креативных шагов seed НЕ передаём — остаются вариативными.
LLM_SEED_STRUCT=1
# Совместимость; не используется, если явно не пробрасывать в коде:
LLM_SEED=1

# --- Temperatures ---
EFFECTS_TEMPERATURE=0.0
PRIVATE_TEMPERATURE=0.65
GENERAL_TEMPERATURE=0.65
SESSION_INIT_TEMPERATURE=0.85

# --- Max tokens ---
EFFECTS_N_PREDICT=400
PRIVATE_N_PREDICT=350
GENERAL_N_PREDICT=450
SESSION_INIT_N_PREDICT=1000

# --- Timeouts (sec) ---
LLM_HTTP_TIMEOUT=180     
LLM_TIMEOUT=180          
SESSION_INIT_TIMEOUT=180 

# --- Turn loop / worker ---
ACTION_WAIT_TIMEOUT=60  
PLAYER_IDLE_POLL=0.5
BOT_SEND_PAUSE=0.25
TURN_COOLDOWN=1.0

# --- Logging ---
LOG_LEVEL=INFO
LOG_LLM_FULL=1
LLM_LOG_CONTENT=1